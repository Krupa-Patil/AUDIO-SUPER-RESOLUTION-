# -*- coding: utf-8 -*-
"""--audio--.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/18c3sa_3JXOinPCdbVfW-piTBhVuYT-ak
"""

from google.colab import drive
drive.mount('/content/drive')

import numpy as np
import tensorflow as tf
from scipy import signal, io, interpolate
import glob
import librosa
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

patch_len = 6000    # Length per time series sample
scale = 2           # Downsampling factor for our corruption


def get_dataset_iterator(batch_size=128, train_size=18000, test_size=5000, VCTK=True):

    
    # @tf.function
    def extract_patches(file_path):
        audio, sr = tf.audio.decode_wav(tf.io.read_file(file_path))
        audio = tf.squeeze(audio)

        # add dimensions so that we can treat the audio file like an image
        audio = tf.expand_dims(tf.expand_dims(tf.expand_dims(audio, -1), 0), 0)

        # borrow the extract_patches function to create patches. you can think of this
        # as convolving on a 1d image to create patches
        patches = tf.image.extract_patches(images=audio, sizes=[1, 1, patch_len, 1], strides=[1, 1, 1, 1], rates=[1, 1, 1, 1], padding='VALID')
        patches = tf.squeeze(patches)
        return tf.data.Dataset.from_tensor_slices(patches)

    # NOTE: you must run download.py first
    dir_path = '/content/drive/MyDrive/VCTK-Corpus/wav48/**/*.wav'
    dataset = tf.data.Dataset.list_files(dir_path)

    # NOTE: To parallelize this, we have to use dataset.map(), and then flatten after
    dataset = dataset.flat_map(map_func=extract_patches)

    # Repeat the dataset for 4 epochs
    dataset = dataset.repeat(2)

    # Need to shuffle again after creating patches
    dataset = dataset.shuffle(buffer_size=250000)

    # Split dataset in train and test
    train_dataset = dataset.take(train_size)
    train_dataset = train_dataset.batch(batch_size, drop_remainder=True)
    test_dataset = dataset.skip(train_size).take(test_size)
    test_dataset = test_dataset.batch(batch_size, drop_remainder=True)

    train_dataset = train_dataset.prefetch(1)
    test_dataset = test_dataset.prefetch(1)

    return train_dataset, test_dataset

def get_demos():
    wav_filepaths = glob.glob("./content/drive/MyDrive/demo/*.wav")
    wav_files, sampling_rates = zip(*[librosa.load(f) for f in wav_filepaths])
    wav_files = list(wav_files)
    sampling_rates = list(sampling_rates)
    for i in range(len(wav_files)):
        wav_files[i] = wav_files[i][:patch_len * 10]
    return wav_filepaths, wav_files, sampling_rates



def get_stft(signal, n_fft):
    return librosa.stft(signal, n_fft)


def amplitude_to_decibel(signal):
    return librosa.core.amplitude_to_db(signal)

class AtrousConv1D(tf.keras.layers.Layer):
    def __init__(self,
                 filters,
                 kernel_size,
                 dilation_rate,
                 use_bias=True,
                 kernel_initializer=tf.keras.initializers.GlorotNormal(),
                 causal=True
                ):
        super(AtrousConv1D, self).__init__()
        self.filters = filters
        self.kernel_size = kernel_size
        self.dilation_rate = dilation_rate
        self.causal = causal
        # Convolution with dilation
        self.conv1d = tf.keras.layers.Conv1D(
            filters=filters,
            kernel_size=kernel_size,
            dilation_rate=dilation_rate,
            padding='valid' if causal else 'same',
            use_bias=use_bias,
            kernel_initializer=kernel_initializer
        )
        
    # def call(self, inputs):
    #     # If padding 'valid', the shape of tensor change.
    #     if self.causal:
    #         padding = (self.kernel_size - 1) * self.dilation_rate
    #         inputs = tf.pad(inputs, tf.constant([(0, 0,), (1, 0), (0, 0)]) * padding)
    #     return self.conv1d(inputs)

import tensorflow as tf
import os
import librosa
import numpy as np
import scipy
from tensorflow.keras.layers import LeakyReLU, Conv1D, Conv2D, BatchNormalization, Conv2DTranspose, Dropout
# from preprocess import get_stft, amplitude_to_decibel
import matplotlib
from matplotlib import pyplot as plt
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'


def subpixel_shuffle(input):
    (batch_size, dim, filters) = input.shape
    input = tf.reshape(input, [batch_size, dim, filters // 2, 2])
    input = tf.transpose(input, [0, 1, 3, 2])
    input = tf.reshape(input, [batch_size, dim * 2, filters // 2])
    return input


"""
    Downsampling blocks for bottleneck architecture
"""
class Encoder(tf.keras.layers.Layer):
    def __init__(self):
        super(Encoder, self).__init__()

        self.encoder_conv_1 = Conv2D(filters=128, kernel_size=65, strides=2, padding='same', dilation=2, activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.encoder_conv_2 = Conv2D(filters=256, kernel_size=33, strides=2, padding='same', dilation=2, activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.encoder_conv_3 = Conv2D(filters=512, kernel_size=17, strides=2, padding='same', dilation=2, activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))

        self.batch_norm_1 = tf.nn.atrous_conv2d(value=65, filters=128, rate=-1, padding='same', name=None)
        self.batch_norm_2 = tf.nn.atrous_conv2d(value=33, filters=256, rate=-1, padding='same', name=None)
        self.batch_norm_3 = tf.nn.atrous_conv2d(value=17, filters=512, rate=-1, padding='same', name=None)

        self.encoder_conv_1 = Conv1D(filters=128, kernel_size=65, dilation_rate=2, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.encoder_conv_2 = Conv1D(filters=256, kernel_size=33, dilation_rate=4, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.encoder_conv_3 = Conv1D(filters=512, kernel_size=17, dilation_rate=8, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))

        self.encoder_conv_1 = AtrousConv1D(filters=128, kernel_size=65, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.encoder_conv_2 = AtrousConv1D(filters=256, kernel_size=33, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.encoder_conv_3 = AtrousConv1D(filters=512, kernel_size=17, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        
        self.batch_norm_1 = BatchNormalization()
        self.batch_norm_2 = BatchNormalization()
        self.batch_norm_3 = BatchNormalization()

    @tf.function
    def call(self, samples):
        
        output_1 = self.batch_norm_1(self.encoder_conv_1(samples))
        output_2 = self.batch_norm_2(self.encoder_conv_2(output_1))
        output_3 = self.batch_norm_3(self.encoder_conv_3(output_2))
        return [output_1, output_2, output_3]


"""
    Upsampling blocks for bottleneck architecture
"""
class Decoder(tf.keras.layers.Layer):
    def __init__(self):
        super(Decoder, self).__init__()


        self.decoder_conv_1 = Conv1D(filters=1024, kernel_size=9, strides=1, padding='same', dilation=2, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.decoder_conv_2 = Conv1D(filters=512, kernel_size=17, strides=1, padding='same', dilation=2, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.decoder_conv_3 = Conv1D(filters=256, kernel_size=33, strides=1, padding='same', dilation=2, activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        
        self.decoder_conv_1 = tf.nn.atrous_conv2d(value=9, filters=1024, rate=-1, padding='same', name=None)
        self.decoder_conv_2 = tf.nn.atrous_conv2d(value=17, filters=512, rate=-1, padding='same', name=None)
        self.decoder_conv_3 = tf.nn.atrous_conv2d(value=33, filters=256, rate=-1, padding='same', name=None)

        self.decoder_conv_1 = Conv1D(filters=1024, kernel_size=9, dilation_rate=8, padding='same', activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.decoder_conv_2 = Conv1D(filters=512, kernel_size=17, dilation_rate=4, padding='same', activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.decoder_conv_3 = Conv1D(filters=256, kernel_size=33, dilation_rate=2, padding='same', activation='relu', kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))

        self.decoder_conv_1 = AtrousConv1D(filters=1024, kernel_size=9, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.decoder_conv_2 = AtrousConv1D(filters=512, kernel_size=17, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.decoder_conv_3 = AtrousConv1D(filters=256, kernel_size=33, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        

        self.batch_norm_1 = BatchNormalization()
        self.batch_norm_2 = BatchNormalization()
        self.batch_norm_3 = BatchNormalization()
        self.dropout = Dropout(0.5)

  
    @tf.function
    def call(self, bottleneck_output, encoder_output):
        output = self.dropout(self.batch_norm_1(self.decoder_conv_1(bottleneck_output)))
        output = subpixel_shuffle(output)

        output = tf.concat([output, encoder_output[2]], axis=-1)

        output = self.dropout(self.batch_norm_2(self.decoder_conv_2(output)))
        output = subpixel_shuffle(output)
        output = tf.concat([output, encoder_output[1]], axis=-1)

        output = self.dropout(self.batch_norm_3(self.decoder_conv_3(output)))
        output = subpixel_shuffle(output)
        output = tf.concat([output, encoder_output[0]], axis=-1)

        return output

class Model(tf.keras.Model):
    def __init__(self):
        super(Model, self).__init__()
        self.encoder = Encoder()
        self.decoder = Decoder()

        self.learning_rate = 10e-4   
        self.batch_size = 128      
        self.epochs = 2          
        self.optimizer = tf.keras.optimizers.Adam(learning_rate=self.learning_rate)

        self.bottleneck_conv = Conv1D(filters=512, kernel_size=9, strides=2, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.bottleneck_conv = AtrousConv1D(filters=512, kernel_size=9, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.final_conv = AtrousConv1D(filters=2, kernel_size=9, dilation_rate=1, kernel_initializer=tf.ones_initializer(), use_bias=False)
        self.final_conv = Conv1D(filters=2, kernel_size=9, strides=1, padding='same', activation=tf.keras.layers.LeakyReLU(alpha=0.2), kernel_initializer=tf.keras.initializers.RandomNormal(mean=0.0, stddev=0.1))
        self.dropout = Dropout(0.5)

    @tf.function
    def call(self, samples):
        encoder_out = self.encoder.call(samples)
        bottleneck_out = self.dropout(self.bottleneck_conv(encoder_out[-1]))
        decoder_out = self.decoder.call(bottleneck_out, encoder_out)
        final_out = tf.cast(samples, tf.float32) + subpixel_shuffle(self.final_conv(decoder_out))
        return final_out

    @tf.function
    def loss_function(self, encoded, originals):
        encoded = tf.dtypes.cast(encoded, tf.float32)
        originals = tf.dtypes.cast(originals, tf.float32)
        return (1/len(encoded)) * tf.math.sqrt(tf.reduce_sum(tf.math.square(tf.norm(originals - tf.reshape(encoded, originals.shape)))))


    def snr_function(self, encoded, originals):
       
        encoded, originals = amplitude_to_decibel(tf.squeeze(encoded)), amplitude_to_decibel(tf.squeeze(originals))  # Convert to decibel
        mean = tf.square(scipy.linalg.norm(originals, axis=1))
        std = tf.square(scipy.linalg.norm(originals-encoded, axis=1))
        snrs = np.where(std==0, 0, 10* tf.math.log(mean/std))
        return tf.reduce_mean(snrs)

    def lsd(self, encoded, originals, n_fft=2048, step=10):
        encoded, originals = amplitude_to_decibel(tf.squeeze(encoded)), amplitude_to_decibel(tf.squeeze(originals))
        S_y = tf.signal.stft(np.array(originals), n_fft, step)
        S_x = tf.signal.stft(np.array(encoded), n_fft, step)
        logspec_y = tf.square(np.log1p(tf.abs(S_y)))
        logspec_x = tf.square(np.log1p(tf.abs(S_x)))
        squared_diff = tf.square(logspec_y - logspec_x)

        return tf.reduce_mean(tf.math.sqrt(squared_diff))

# import os
import numpy as np
import tensorflow as tf
import numpy as np
# from preprocess import get_dataset_iterator, get_demos
# from model import Model
import sys
import time
import soundfile as sf
from scipy.signal import decimate
from scipy import interpolate
import os
os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'

patch_len = 6000
scale = 2


def corrupt_batch(batch):
    corrupted = decimate(batch, scale, axis=-2)  
    corrupted = corrupted.flatten()
    new_length = len(corrupted) * scale

    f = interpolate.splrep(np.arange(new_length, step=scale), corrupted)    
    upscaled = tf.reshape(interpolate.splev(np.arange(new_length), f), (batch.shape[0], -1, 1))
    return upscaled


def train(model, train_data_iterator):
    for iteration, batch in enumerate(train_data_iterator):
        batch = tf.expand_dims(batch, -1)
        batch_corrupted = corrupt_batch(batch)
        assert(batch_corrupted.shape == batch.shape)

        with tf.GradientTape() as tape:
            batch_sharpened = model.call(batch_corrupted)
            loss = model.loss_function(batch_sharpened, batch)
            accuracy = model.snr_function(batch_sharpened, batch)
            lsd = model.lsd(batch_sharpened, batch)

        gradients = tape.gradient(loss, model.trainable_variables)
        model.optimizer.apply_gradients(zip(gradients, model.trainable_variables))

        if iteration % 1  == 0:
            print("BATCH %d LOSS %f SNR %f LSD %f"%(iteration, loss, accuracy, lsd))


def test(model, test_data_iterator):
    losses = []
    accuracies = []
    lsds = []

    for iteration, batch in enumerate(test_data_iterator):
        batch = tf.expand_dims(batch, -1)
        batch_corrupted = corrupt_batch(batch)
        batch_sharpened = model.call(batch_corrupted)
        loss = model.loss_function(batch_sharpened, batch)
        accuracy = model.snr_function(batch_sharpened, batch)
        losses.append(loss)
        accuracies.append(accuracy)
        lsds.append(model.lsd(batch_sharpened, batch))

    return tf.reduce_mean(losses), tf.reduce_mean(accuracies), tf.reduce_mean(lsds)


def test_demo(model):
    wav_filepaths, wav_files, sampling_rates = get_demos()
    output_dir = '/content/drive/MyDrive/demo/output/'
    if not os.path.exists(output_dir):
        os.makedirs(output_dir)

    for i in range(len(wav_files)):

        batch = tf.expand_dims(tf.expand_dims(wav_files[i], 0), -1)
        batch_corrupted = corrupt_batch(batch)
        batch_sharpened = model.call(batch_corrupted)
       
        sf.write(file=os.path.join(output_dir, str(i + 1)+'_sharpened.wav'), data=tf.squeeze(batch_sharpened), samplerate=sampling_rates[i])
        sf.write(file=os.path.join(output_dir, str(i + 1)+'_corrupted.wav'), data=tf.squeeze(batch_corrupted), samplerate=sampling_rates[i])
        sf.write(file=os.path.join(output_dir, str(i + 1)+'_original.wav'), data=tf.squeeze(batch), samplerate=sampling_rates[i])
        

def main():
    model = Model()

    print("Running preprocessing...")
    train_data_iterator, test_data_iterator = get_dataset_iterator(batch_size=model.batch_size, VCTK=True)
    print("Finished reprocessing.")

    print("Beginning training...")
    for epoch in range(model.epochs):
        print("EPOCH %d" % epoch)
        train(model, train_data_iterator)
    print("Training complete.")

    print("Beginning testing...")
    loss, accuracy, lsds = test(model, test_data_iterator)
    print("Average loss: " + str(loss.numpy()))
    print("Average accuracy (SNR): " + str(accuracy.numpy()))
    print("Average accuracy (LSD): " + str(lsds.numpy()))

    test_demo(model)

if __name__ == '__main__':
   main()

